{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f4DS3H43eQVI",
        "outputId": "43bcd8a1-4968-4be1-92d2-97449b03ae9e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Collecting textblob\n",
            "  Downloading textblob-0.18.0.post0-py3-none-any.whl.metadata (4.5 kB)\n",
            "Requirement already satisfied: nltk>=3.8 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.9.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8->textblob) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8->textblob) (1.4.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8->textblob) (2024.9.11)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.8->textblob) (4.66.6)\n",
            "Downloading textblob-0.18.0.post0-py3-none-any.whl (626 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m626.3/626.3 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: textblob\n",
            "  Attempting uninstall: textblob\n",
            "    Found existing installation: textblob 0.17.1\n",
            "    Uninstalling textblob-0.17.1:\n",
            "      Successfully uninstalled textblob-0.17.1\n",
            "Successfully installed textblob-0.18.0.post0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/brown.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger_eng.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tokens: ['on', 'october', '15', ',', '2024', ',', 'elon', 'musk', 'announced', 'a', 'major', 'update', 'on', 'tesla', \"'s\", 'new', 'ai', 'project', 'during', 'a', 'conference', 'in', 'san', 'francisco', '.', 'the', 'event', 'was', 'attended', 'by', 'over', '1,000', 'engineers', 'and', 'scientists', 'from', 'different', 'parts', 'of', 'the', 'world', '.', 'in', 'his', 'keynote', ',', 'musk', 'highlighted', 'the', 'advancements', 'in', 'ai-driven', 'electric', 'vehicles', ',', 'predicting', 'that', 'tesla', \"'s\", 'self-driving', 'cars', 'will', 'hit', 'the', 'roads', 'by', '2025.', 'he', 'also', 'shared', 'updates', 'on', 'spacex', \"'s\", 'plans', 'for', 'the', 'mars', 'mission', ',', 'set', 'to', 'take', 'place', 'in', 'the', 'late', '2030s', '.', 'several', 'experts', ',', 'including', 'dr.', 'jane', 'doe', 'from', 'mit', ',', 'expressed', 'optimism', 'about', 'these', 'futuristic', 'technologies', '.', 'the', 'stock', 'prices', 'of', 'tesla', 'and', 'spacex', 'surged', 'by', '5', '%', 'the', 'following', 'day', '.']\n",
            "\n",
            "\n",
            "Text without special characters: On October 15 2024 Elon Musk announced a major update on Teslas new AI project during a conference in San Francisco\n",
            "   The event was attended by over 1000 engineers and scientists from different parts of the world\n",
            "   In his keynote Musk highlighted the advancements in AIdriven electric vehicles predicting that Teslas selfdriving cars\n",
            "   will hit the roads by 2025 He also shared updates on SpaceXs plans for the Mars mission set to take place in the late 2030s\n",
            "   Several experts including Dr Jane Doe from MIT expressed optimism about these futuristic technologies\n",
            "   The stock prices of Tesla and SpaceX surged by 5 the following day\n",
            "\n",
            "\n",
            "Expanded Contractions: In October 15, 2024, On Dusk announced a major update on Cela's new of project during a conference in An Francisco.\n",
            "   The event was attended by over 1,000 engineers and scientists from different parts of the world.\n",
            "   In his denote, Dusk highlight the advancement in of-driven electric vehicles, predictions that Cela's self-driving cars\n",
            "   will hit the roads by 2025. He also shared updated on space's plans for the Wars mission, set to take place in the late 2030s.\n",
            "   Several experts, including Or. Lane Toe from MIT, expressed optimism about these futuristic technologies.\n",
            "   The stock prices of Cela and space urged by 5% the following day.\n",
            "\n",
            "\n",
            "Tokens without stop words: ['october', '15', ',', '2024', ',', 'elon', 'musk', 'announced', 'major', 'update', 'tesla', \"'s\", 'new', 'ai', 'project', 'conference', 'san', 'francisco', '.', 'event', 'attended', '1,000', 'engineers', 'scientists', 'different', 'parts', 'world', '.', 'keynote', ',', 'musk', 'highlighted', 'advancements', 'ai-driven', 'electric', 'vehicles', ',', 'predicting', 'tesla', \"'s\", 'self-driving', 'cars', 'hit', 'roads', '2025.', 'also', 'shared', 'updates', 'spacex', \"'s\", 'plans', 'mars', 'mission', ',', 'set', 'take', 'place', 'late', '2030s', '.', 'several', 'experts', ',', 'including', 'dr.', 'jane', 'doe', 'mit', ',', 'expressed', 'optimism', 'futuristic', 'technologies', '.', 'stock', 'prices', 'tesla', 'spacex', 'surged', '5', '%', 'following', 'day', '.']\n",
            "\n",
            "\n",
            "Corrected Text: In October 15, 2024, On Dusk announced a major update on Cela's new of project during a conference in An Francisco.\n",
            "   The event was attended by over 1,000 engineers and scientists from different parts of the world.\n",
            "   In his denote, Dusk highlight the advancement in of-driven electric vehicles, predictions that Cela's self-driving cars\n",
            "   will hit the roads by 2025. He also shared updated on space's plans for the Wars mission, set to take place in the late 2030s.\n",
            "   Several experts, including Or. Lane Toe from MIT, expressed optimism about these futuristic technologies.\n",
            "   The stock prices of Cela and space urged by 5% the following day.\n",
            "\n",
            "\n",
            "Stemmed Tokens: ['on', 'octob', '15', ',', '2024', ',', 'elon', 'musk', 'announc', 'a', 'major', 'updat', 'on', 'tesla', \"'s\", 'new', 'ai', 'project', 'dure', 'a', 'confer', 'in', 'san', 'francisco', '.', 'the', 'event', 'wa', 'attend', 'by', 'over', '1,000', 'engin', 'and', 'scientist', 'from', 'differ', 'part', 'of', 'the', 'world', '.', 'in', 'hi', 'keynot', ',', 'musk', 'highlight', 'the', 'advanc', 'in', 'ai-driven', 'electr', 'vehicl', ',', 'predict', 'that', 'tesla', \"'s\", 'self-driv', 'car', 'will', 'hit', 'the', 'road', 'by', '2025.', 'he', 'also', 'share', 'updat', 'on', 'spacex', \"'s\", 'plan', 'for', 'the', 'mar', 'mission', ',', 'set', 'to', 'take', 'place', 'in', 'the', 'late', '2030', '.', 'sever', 'expert', ',', 'includ', 'dr.', 'jane', 'doe', 'from', 'mit', ',', 'express', 'optim', 'about', 'these', 'futurist', 'technolog', '.', 'the', 'stock', 'price', 'of', 'tesla', 'and', 'spacex', 'surg', 'by', '5', '%', 'the', 'follow', 'day', '.']\n",
            "\n",
            "\n",
            "Lemmatized Tokens: ['on', 'october', '15', ',', '2024', ',', 'elon', 'musk', 'announced', 'a', 'major', 'update', 'on', 'tesla', \"'s\", 'new', 'ai', 'project', 'during', 'a', 'conference', 'in', 'san', 'francisco', '.', 'the', 'event', 'wa', 'attended', 'by', 'over', '1,000', 'engineer', 'and', 'scientist', 'from', 'different', 'part', 'of', 'the', 'world', '.', 'in', 'his', 'keynote', ',', 'musk', 'highlighted', 'the', 'advancement', 'in', 'ai-driven', 'electric', 'vehicle', ',', 'predicting', 'that', 'tesla', \"'s\", 'self-driving', 'car', 'will', 'hit', 'the', 'road', 'by', '2025.', 'he', 'also', 'shared', 'update', 'on', 'spacex', \"'s\", 'plan', 'for', 'the', 'mar', 'mission', ',', 'set', 'to', 'take', 'place', 'in', 'the', 'late', '2030s', '.', 'several', 'expert', ',', 'including', 'dr.', 'jane', 'doe', 'from', 'mit', ',', 'expressed', 'optimism', 'about', 'these', 'futuristic', 'technology', '.', 'the', 'stock', 'price', 'of', 'tesla', 'and', 'spacex', 'surged', 'by', '5', '%', 'the', 'following', 'day', '.']\n",
            "\n",
            "\n",
            "Aggregated Features: {'word_count': 122, 'char_count': 658, 'sentence_count': 6}\n",
            "\n",
            "\n",
            "Date-Time Features: {'current_date': datetime.date(2024, 11, 26), 'current_time': datetime.time(17, 21, 4, 385231), 'year': 2024, 'month': 11, 'day': 26, 'hour': 17, 'minute': 21}\n",
            "\n",
            "\n",
            "Sentiment: {'polarity': -0.016856060606060607, 'subjectivity': 0.3757575757575758}\n",
            "\n",
            "\n",
            "Nouns: ['update', 'project', 'conference', 'event', 'world', 'keynote', 'mission', 'place', 'optimism', 'stock', '%', 'day']\n",
            "\n",
            "\n",
            "Named Entities: [('October 15, 2024', 'DATE'), ('Elon Musk', 'PERSON'), ('Tesla', 'ORG'), ('AI', 'ORG'), ('San Francisco', 'GPE'), ('over 1,000', 'CARDINAL'), ('Musk', 'PERSON'), ('Tesla', 'ORG'), ('2025', 'DATE'), ('SpaceX', 'ORG'), ('Mars', 'LOC'), ('the late 2030s', 'DATE'), ('Jane', 'PERSON'), ('MIT', 'ORG'), ('Tesla', 'ORG'), ('5%', 'PERCENT'), ('the following day', 'DATE')]\n",
            "\n",
            "\n",
            "POS Tags: [('On', 'ADP'), ('October', 'PROPN'), ('15', 'NUM'), (',', 'PUNCT'), ('2024', 'NUM'), (',', 'PUNCT'), ('Elon', 'PROPN'), ('Musk', 'PROPN'), ('announced', 'VERB'), ('a', 'DET'), ('major', 'ADJ'), ('update', 'NOUN'), ('on', 'ADP'), ('Tesla', 'PROPN'), (\"'s\", 'PART'), ('new', 'ADJ'), ('AI', 'PROPN'), ('project', 'NOUN'), ('during', 'ADP'), ('a', 'DET'), ('conference', 'NOUN'), ('in', 'ADP'), ('San', 'PROPN'), ('Francisco', 'PROPN'), ('.', 'PUNCT'), ('\\n   ', 'SPACE'), ('The', 'DET'), ('event', 'NOUN'), ('was', 'AUX'), ('attended', 'VERB'), ('by', 'ADP'), ('over', 'ADP'), ('1,000', 'NUM'), ('engineers', 'NOUN'), ('and', 'CCONJ'), ('scientists', 'NOUN'), ('from', 'ADP'), ('different', 'ADJ'), ('parts', 'NOUN'), ('of', 'ADP'), ('the', 'DET'), ('world', 'NOUN'), ('.', 'PUNCT'), ('\\n   ', 'SPACE'), ('In', 'ADP'), ('his', 'PRON'), ('keynote', 'NOUN'), (',', 'PUNCT'), ('Musk', 'PROPN'), ('highlighted', 'VERB'), ('the', 'DET'), ('advancements', 'NOUN'), ('in', 'ADP'), ('AI', 'PROPN'), ('-', 'PUNCT'), ('driven', 'VERB'), ('electric', 'ADJ'), ('vehicles', 'NOUN'), (',', 'PUNCT'), ('predicting', 'VERB'), ('that', 'SCONJ'), ('Tesla', 'PROPN'), (\"'s\", 'PART'), ('self', 'NOUN'), ('-', 'PUNCT'), ('driving', 'VERB'), ('cars', 'NOUN'), ('\\n   ', 'SPACE'), ('will', 'AUX'), ('hit', 'VERB'), ('the', 'DET'), ('roads', 'NOUN'), ('by', 'ADP'), ('2025', 'NUM'), ('.', 'PUNCT'), ('He', 'PRON'), ('also', 'ADV'), ('shared', 'VERB'), ('updates', 'NOUN'), ('on', 'ADP'), ('SpaceX', 'PROPN'), (\"'s\", 'PART'), ('plans', 'NOUN'), ('for', 'ADP'), ('the', 'DET'), ('Mars', 'PROPN'), ('mission', 'NOUN'), (',', 'PUNCT'), ('set', 'VERB'), ('to', 'PART'), ('take', 'VERB'), ('place', 'NOUN'), ('in', 'ADP'), ('the', 'DET'), ('late', 'ADJ'), ('2030s', 'NUM'), ('.', 'PUNCT'), ('\\n   ', 'SPACE'), ('Several', 'ADJ'), ('experts', 'NOUN'), (',', 'PUNCT'), ('including', 'VERB'), ('Dr.', 'PROPN'), ('Jane', 'PROPN'), ('Doe', 'PROPN'), ('from', 'ADP'), ('MIT', 'PROPN'), (',', 'PUNCT'), ('expressed', 'VERB'), ('optimism', 'NOUN'), ('about', 'ADP'), ('these', 'DET'), ('futuristic', 'ADJ'), ('technologies', 'NOUN'), ('.', 'PUNCT'), ('\\n   ', 'SPACE'), ('The', 'DET'), ('stock', 'NOUN'), ('prices', 'NOUN'), ('of', 'ADP'), ('Tesla', 'PROPN'), ('and', 'CCONJ'), ('SpaceX', 'PROPN'), ('surged', 'VERB'), ('by', 'ADP'), ('5', 'NUM'), ('%', 'NOUN'), ('the', 'DET'), ('following', 'ADJ'), ('day', 'NOUN'), ('.', 'PUNCT')]\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!pip install -U textblob\n",
        "import re\n",
        "import string\n",
        "import nltk\n",
        "import spacy\n",
        "from textblob import TextBlob\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
        "from datetime import datetime\n",
        "\n",
        "\n",
        "# Download necessary NLTK data\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')\n",
        "nltk.download('punkt')\n",
        "nltk.download('brown')\n",
        "nltk.download('averaged_perceptron_tagger_eng')\n",
        "# Load Spacy model\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "\n",
        "\n",
        "# 1. Text Preprocessing Functions\n",
        "\n",
        "\n",
        "# Tokenization and Lowercasing\n",
        "def tokenize_and_lowercase(text):\n",
        "   tokens = word_tokenize(text.lower())\n",
        "   return tokens\n",
        "\n",
        "\n",
        "# Remove Special Characters\n",
        "def remove_special_characters(text):\n",
        "   return re.sub(r'[^A-Za-z0-9\\s]', '', text)\n",
        "\n",
        "\n",
        "# Contraction Expansion using TextBlob\n",
        "def expand_contractions(text):\n",
        "   return str(TextBlob(text).correct())\n",
        "\n",
        "\n",
        "# Remove Stop Words\n",
        "def remove_stop_words(tokens):\n",
        "   stop_words = set(stopwords.words('english'))\n",
        "   return [word for word in tokens if word not in stop_words]\n",
        "\n",
        "\n",
        "# Correct Spelling using TextBlob\n",
        "def correct_spelling(text):\n",
        "   return str(TextBlob(text).correct())\n",
        "\n",
        "\n",
        "# Stemming\n",
        "def perform_stemming(tokens):\n",
        "   stemmer = PorterStemmer()\n",
        "   return [stemmer.stem(word) for word in tokens]\n",
        "\n",
        "\n",
        "# Lemmatization\n",
        "def perform_lemmatization(tokens):\n",
        "   lemmatizer = WordNetLemmatizer()\n",
        "   return [lemmatizer.lemmatize(word) for word in tokens]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 2. Feature Extraction Functions\n",
        "\n",
        "\n",
        "# Aggregated Features\n",
        "def get_aggregated_features(text):\n",
        "   word_count = len(word_tokenize(text))\n",
        "   char_count = len(text)\n",
        "   sentence_count = len(nltk.sent_tokenize(text))\n",
        "   return {'word_count': word_count, 'char_count': char_count, 'sentence_count': sentence_count}\n",
        "\n",
        "\n",
        "# Date-Time Features\n",
        "def get_datetime_features():\n",
        "   now = datetime.now()\n",
        "   return {\n",
        "       'current_date': now.date(),\n",
        "       'current_time': now.time(),\n",
        "       'year': now.year,\n",
        "       'month': now.month,\n",
        "       'day': now.day,\n",
        "       'hour': now.hour,\n",
        "       'minute': now.minute\n",
        "   }\n",
        "\n",
        "\n",
        "# Sentiment Analysis using TextBlob\n",
        "def get_sentiment(text):\n",
        "   sentiment = TextBlob(text).sentiment\n",
        "   return {'polarity': sentiment.polarity, 'subjectivity': sentiment.subjectivity}\n",
        "\n",
        "\n",
        "# Extraction of Nouns\n",
        "def extract_nouns(text):\n",
        "   blob = TextBlob(text)\n",
        "   return [word for word, pos in blob.tags if pos == 'NN']\n",
        "\n",
        "\n",
        "# NLP-Based Features: Named Entity Recognition\n",
        "def get_named_entities(text):\n",
        "   doc = nlp(text)\n",
        "   return [(ent.text, ent.label_) for ent in doc.ents]\n",
        "\n",
        "\n",
        "# NLP-Based Features: POS Tagging\n",
        "def get_pos_tags(text):\n",
        "   doc = nlp(text)\n",
        "   return [(token.text, token.pos_) for token in doc]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "   # Sample text\n",
        "   text = \"\"\"On October 15, 2024, Elon Musk announced a major update on Tesla's new AI project during a conference in San Francisco.\n",
        "   The event was attended by over 1,000 engineers and scientists from different parts of the world.\n",
        "   In his keynote, Musk highlighted the advancements in AI-driven electric vehicles, predicting that Tesla's self-driving cars\n",
        "   will hit the roads by 2025. He also shared updates on SpaceX's plans for the Mars mission, set to take place in the late 2030s.\n",
        "   Several experts, including Dr. Jane Doe from MIT, expressed optimism about these futuristic technologies.\n",
        "   The stock prices of Tesla and SpaceX surged by 5% the following day.\"\"\"\n",
        "\n",
        "\n",
        "   # Preprocessing\n",
        "   tokens = tokenize_and_lowercase(text)\n",
        "   print(f\"Tokens: {tokens}\")\n",
        "   print(\"\\n\")\n",
        "\n",
        "   text_no_special = remove_special_characters(text)\n",
        "   print(f\"Text without special characters: {text_no_special}\")\n",
        "   print(\"\\n\")\n",
        "\n",
        "   expanded_text = expand_contractions(text)\n",
        "   print(f\"Expanded Contractions: {expanded_text}\")\n",
        "   print(\"\\n\")\n",
        "\n",
        "   tokens_no_stopwords = remove_stop_words(tokens)\n",
        "   print(f\"Tokens without stop words: {tokens_no_stopwords}\")\n",
        "   print(\"\\n\")\n",
        "\n",
        "\n",
        "   corrected_text = correct_spelling(text)\n",
        "   print(f\"Corrected Text: {corrected_text}\")\n",
        "   print(\"\\n\")\n",
        "\n",
        "\n",
        "   stemmed_tokens = perform_stemming(tokens)\n",
        "   print(f\"Stemmed Tokens: {stemmed_tokens}\")\n",
        "   print(\"\\n\")\n",
        "\n",
        "\n",
        "   lemmatized_tokens = perform_lemmatization(tokens)\n",
        "   print(f\"Lemmatized Tokens: {lemmatized_tokens}\")\n",
        "   print(\"\\n\")\n",
        "\n",
        "\n",
        "   # Feature Extraction\n",
        "   aggregated_features = get_aggregated_features(text)\n",
        "   print(f\"Aggregated Features: {aggregated_features}\")\n",
        "   print(\"\\n\")\n",
        "\n",
        "   datetime_features = get_datetime_features()\n",
        "   print(f\"Date-Time Features: {datetime_features}\")\n",
        "   print(\"\\n\")\n",
        "   sentiment = get_sentiment(text)\n",
        "   print(f\"Sentiment: {sentiment}\")\n",
        "   print(\"\\n\")\n",
        "   nouns = extract_nouns(text)\n",
        "   print(f\"Nouns: {nouns}\")\n",
        "   print(\"\\n\")\n",
        "   named_entities = get_named_entities(text)\n",
        "   print(f\"Named Entities: {named_entities}\")\n",
        "   print(\"\\n\")\n",
        "   pos_tags = get_pos_tags(text)\n",
        "   print(f\"POS Tags: {pos_tags}\")\n",
        "   print(\"\\n\")"
      ]
    }
  ]
}